小结：
1、windows环境安装MongoDB；
2、学习JavaAPI，了解了用Java如何去操作DB，依赖mongo-java-driver包和morphia.jar包
3、基于spring-data-mongodb.jar手写 mongodb orm 框架
4、Linux环境安装配置MongoDB，及服务端启动，客户端连接服务端操作服务端；
5、实战阶段，MongoDB高可用解决方案；
------------------------利用spring-data-mongodb.jar手写 mongodb orm 框架-------------------------
目的：调用监控，aop埋点，性能监控，统一规范，读写分离，分布式集群，动态路由；
1、创建 HotelDao extends BaseDaoSupport<Hotel, Long>，里面用到 QueryRule.java 类，自己定义该类，创建
QueryRuleBulider.java；
2、HotelDaoTest.java
定义testFind()方法：
 @Test
	public  void testFind(){
		this.hotelDao.getByName("麓谷大酒店");
	}
跟 getByName()方法，进入 HotelDao类的getByName()方法，跟里面的super.find()方法，进入BaseDaoSuport类
的find()方法，在这个find方法中，首先应该拿到 template，这个template在application-db.xml中已经声明好了
①那么这个 template怎么以友好的方式注入 find 方法的类 BaseDaoSupport 类呢，BaseDaoSupport是抽象类，不
能通过 new 调用构造方法，生成对象；
②如何将用户的QueryRule操作转换为template操作；
③MongoDB肯定需要实现读写分离，以及动态数据源如何路由；
3、HotelDaoTest类中注入 mongoTemplate 对象；HotelDaoTest类的 testFind()方法中 this.mongoTemplate.find();
调用mongoTemplate的find方法，该find(query,entityClass)需要两个参数，先不管其他，将这两个参数的对象new
处理，返回Hotel的list集合；利用 JSON.toJSONString(对象)方法，将对象转换为JSON格式的字符串；

@Document(collection="t_hotel")
public class Hotel implements Serializable {...} Hotel类上加注解 Document java中实体类与mongodb中集合
collection关联起来；
----------------------------第二次课 2-------------------------------------------------------------
+ BaseDaoSupport类
public abstract class BaseDaoSupport<T extends Serializable, PK extends Serializable> {
	protected List<T> find(QueryRule queryRule){

		return null;
	}
}
注意泛型用法；
该类里面定义BaseDaoSupport方法：
public BaseDaoSupport() {
	Class<T> entityClass = GenericsUtils.getSuperClassGenricType(this.getClass(),0);
	new EntityOperation<T>(entityClass);
}
再定义属性：
private MongoTemplate mongoTemplate;
private EntityOperation op;
将mongoTemplate跟op保存起来；
定义setMongoTemplate方法，目的：注入 mongoTemplate
public void setMongoTemplate(MongoTemplate mongoTemplate) {
	this.mongoTemplate = mongoTemplate;
}
定义getPKColumn()抽象方法，
protected abstract String getPKColumn();

+ HotelDao继承BaseDaoSupport
@Repository
public class HotelDao extends BaseDaoSupport<Hotel, Long> {

}
定义getPKColumn()实现父类抽象方法
@Override
protected String getPKColumn() {
	return "_id";
}
定义setMongoTemplate()方法，@Resouce直接将spring容器中的对象地址赋给该方法的参数对象；
@Resource(name="mongoTemplate")
public void setMongoTemplate(MongoTemplate mongoTemplate) {
	super.setMongoTemplate(mongoTemplate);
}
+ 回到BaseDaoSupport类
find(QueryRule queryRule)方法
protected List<T> find(QueryRule queryRule){
	Query query = new Query();
	return this.mongoTemplate.find(query,op.entityClass);
}
+ 测试类 HotelDaoTest，不需要注入 @Autowired MongoTemplate mongoTemplate;
public class HotelDaoTest {
	@Autowired
	HotelDao hotelDao;
}
定义方法 testFind()，该方法里面调用父类的 super.find(QueryRule queryRule)方法
public  void testFind(){
	List<Hotel> result = this.hotelDao.getAll();
	String jsonStr = JSON.toJSONString(result);
	System.out.println(jsonStr);
}
+ 类 BaseDaoSupport中find(QueryRule queryRule)方法,怎么样与queryRule建立关系？
public abstract class BaseDaoSupport<T extends Serializable, PK extends Serializable> {
	private MongoTemplate mongoTemplate;
	private EntityOperation op;

	public BaseDaoSupport() {
		Class<T> entityClass = GenericsUtils.getSuperClassGenricType(this.getClass(),0);
		this.op = new EntityOperation<T>(entityClass);
	}
    protected List<T> find(QueryRule queryRule){
    	Query query = new Query();
    	return this.mongoTemplate.find(query,op.entityClass);
    }
}
find()方法中，创建 criteria对象 Criteria criteria = new Criteria();将该对象传递给query对象，
Query query = new Query(criteria);

+ 类QueryRuleBulider
public class QueryRuleBulider {

}
里面创建getQuery()方法，用于获取query对象；
public Query getQuery(){
	Criteria criteria = new Criteria();
	Query query = new Query(criteria);
	return query;
}
构造方法，循环QueryRuleList，动态生成Criteria
public QueryRuleBulider(QueryRule queryRule){
	/*根据 RuleList来循环，动态生成各种Criteria*/
	queryRule.getRuleList();
}

+ 回到 BaseDaoSupport类的find()方法：
protected List<T> find(QueryRule queryRule){
    ①
	/*Criteria criteria = new Criteria();
	Query query = new Query(criteria);*/
	----------------------------------------------------
	②
	QueryRuleBulider bulider = new QueryRuleBulider(queryRule);
    Query query = bulider.getQuery();
	return this.mongoTemplate.find(query,op.entityClass);
}
②相对①，可以根据queryRule自己生成相应的query，不用自己到处定义，直接用自己定义的类里面的方法就可以；
+ 运行 HotelDaoTest类的testFind()方法；

补充 HotelDao类的方法 getById()：
public Hotel getById(String id){
	QueryRule queryRule = QueryRule.getInstance();
	queryRule.andEqual(this.getPKColumn(),id);
	super.find(queryRule);
	return null;
}
跟super.find()方法，进入 BaseDaoSupport类的 find(QueryRule queryRule)方法：
protected List<T> find(QueryRule queryRule){
	QueryRuleBulider bulider = new QueryRuleBulider(queryRule);
	Query query = bulider.getQuery();
	return mongoTemplate.find(query, op.entityClass);
}
跟  new QueryRuleBulider(queryRule);进入QueryRuleBulider类的构造方法：
public class QueryRuleBulider {
	public QueryRuleBulider(QueryRule queryRule){
		/*根据 RuleList来循环，动态生成各种Criteria*/
		queryRule.getRuleList();
	}
	public Query getQuery(){
		Criteria criteria = new Criteria();
		Query query = new Query(criteria);
		return query;
	}
}
完善该类：
将 Query query，Criteria criteria提为属性：属性为全局变量，各方法共享，方法内为局部变量，各方法独有；
修改 构造方法 QueryRuleBulider(QueryRule queryRule)，循环规则queryRule，调用对应方法：
public QueryRuleBulider(QueryRule queryRule){
		/*根据 RuleList来循环，动态生成各种Criteria*/
		this.criteria = new Criteria();
        for (QueryRule.Rule rule : queryRule.getRuleList()) {
            switch (rule.getType()) {
                case QueryRule.BETWEEN:
                    processBetween(rule);
                    break;
                case QueryRule.EQ:
                    processEqual(rule);
                    break;
                case QueryRule.LIKE:
                    processLike(rule);
                    break;
                case QueryRule.NOTEQ:
                    processNotEqual(rule);
                    break;
                case QueryRule.GT:
                    processGreaterThen(rule);
                    break;
                case QueryRule.GE:
                    processGreaterEqual(rule);
                    break;
                case QueryRule.LT:
                    processLessThen(rule);
                    break;
                case QueryRule.LE:
                    processLessEqual(rule);
                    break;
                case QueryRule.IN:
                    processIN(rule);
                    break;
                case QueryRule.NOTIN:
                    processNotIN(rule);
                    break;
                case QueryRule.ISNULL:
                    processIsNull(rule);
                    break;
                case QueryRule.ISNOTNULL:
                    processIsNotNull(rule);
                    break;
                case QueryRule.ISEMPTY:
                    processIsEmpty(rule);
                    break;
                case QueryRule.ISNOTEMPTY:
                    processIsNotEmpty(rule);
                    break;
                case QueryRule.ASC_ORDER:
                    processOrder(rule);
                    break;
                case QueryRule.DESC_ORDER:
                    processOrder(rule);
                    break;
                default:
                 throw new IllegalArgumentException("type " + rule.getType() + " not supported.");
           }
       }
	this.query = new Query(this.criteria);
	queryRule.getRuleList();
}
+ 测试类 HotelDaoTest中 testFind()方法
public  void testFind(){
	List<Hotel> result = this.hotelDao.getById("5a9dfcb81c3a3173df927ce7");
	String jsonStr = JSON.toJSONString(result);
	System.out.println(jsonStr);
}
+ QueryRuleBulider类的排序方法 processOrder(QueryRule.Rule rule)：
private void processOrder(QueryRule.Rule rule) {
    /*根据某个字段升序降序*/
    switch (rule.getType()){
        case QueryRule.ASC_ORDER :
            break;
        default:break;
    }
}
+ 修改 HotelDao类的getAll()方法，增加queryRule.addDescOrder("price");表示添加按价格排序规则；
public List<Hotel> getAll(){
     原来的：
	/*
	        QueryRule queryRule = QueryRule.getInstance();
    		return super.find(queryRule);*/
    现在的：
    		QueryRule queryRule = QueryRule.getInstance();
    		queryRule.addDescOrder("price");
    		return super.find(queryRule);
}
修改 QueryRuleBuilder类的 构造方法 ，最后增加 1 句：this.query.with(new Sort(this.orders));
 + 调用 HotelDaoTest类的 testFind()方法；

 mongod的java API操作完成
 ---------------------------------Linux中安装，操作mongodb--------------------------------------
 创建mongodb进程规律：创建一个文件夹，里面包含 ①服务端启动命令 mongod + ②配置文件mongodb.cfg + ③
 data logs文件夹

 1、下载：wget http://...
 2、解压：tar -xzvf ... /usr/local
 3、进入mongdb目录：创建 data文件夹；
 4、进入bin目录，启动：mongod --dbpath=/usr/local/mongodb/data
 5、本地连接：/usr/local/mongodb/bin/mongo，本地可以连接成功，但是外部不能连接；
 6、启动mongodb服务器时绑定服务器 ip ：./mongod --dbpath=/usr/local/mongodb/data --bind_ip=192.168.1.150 --logpath=/usr/local/mongodb/logs/mongodb.log --logappend --fork
 7、远程客户端连接服务端：
 先配置 SSH Tunnel；SSH Address：47.100.49.95；SSH User name：root；SSH Password：Ab216411；
 在配置 Server；server：192.168.1.150；port：27017；
 8、以上启动服务端方式较繁琐，可以使用配置文件启动：
 ①创建 mongodb.cfg 文件：vim /usr/local/mongodb/bin/mongodb.cfg，内容如下：
 dbpath=/usr/local/mongodb/data
 bind_ip=192.168.1.150
 logpath=/usr/local/mongodb/logs/mongodb.log
 logappend=true
 fork=true
 port=27017
 ②启动服务端：./mongod -f mongodb.cfg
 ③查看进程：ps aux | grep mongod
 9、客户端连接服务端：/usr/local/mongodb/bin/mongo --host=192.168.1.150
 -------------------------客户端操作mongodb数据库--------------------------------------------------
 1、帮助：db.help()；展示当前数据库：show dbs；创建 新数据库 testdb：use testdb；
 2、客户端增加用户：db.createUser({user:"tom",pwd:"123",roles:[{role:"dbAdmin",db:"testdb"}]})；
 增加完用户必须启用用户：db.auth({user:"tom",pwd:"123"})
 3、查询/删除用户：先切换到 admin ：use admin；再查询：db.system.users.find();/再删除用户：
 db.system.users.remove({user:"tom",pwd:"123",roles:[{role:"dbAdmin",db:"testdb"}]});
 -----------------------伪分布式：不同端口区分不同服务----------------------------------------------
 1、创建文件夹 master-slave 作伪分布式环境：mkdir -p /usr/local/mongodb/master-slave；该环境下，创建
 master/data文件夹，master/logs文件夹，slave/data文件夹，slave/logs文件夹；
 2、master | slave 文件夹中建立 mongodb.cfg 文件，内容如下：
 主节点配置
 dbpath=/usr/local/mongodb/master-slave/master/data  数据路径
 logpath=/usr/local/mongodb/master-slave/master/logs/mongodb.log  日志路径
 logappend=true  是否可追加日志
 fork=true  是否后台启动
 bind_ip=192.168.1.150  绑定ip
 port=27001  端口
 以下为集群配置
 master=true  是否为主节点
 source=192.168.1.150:27002  集群其他节点ip：port
 从节点配置
 dbpath=/usr/local/mongodb/master-slave/slave/data
 logpath=/usr/local/mongodb/master-slave/slave/logs/mongodb.log
 logappend=true
 fork=true
 bind_ip=192.168.1.150
 port=27002

 slave=true  是否为从节点
 source=192.168.1.150:27001 集群其他节点ip：port
 3、分别启动主节点master与从节点：./mongod -f mongodb.cfg
 4、客户端连接服务端：./mongo --host=192.168.1.150 --port=27001;./mongo --host=192.168.1.150 --port=27002
 客户端连接到服务端后：db.isMaster()检查是否为主节点；
 5、怎么验证主从节点数据是一模一样的呢？
 从节点客户端：rs.slaveOk()，然后，show dbs；
 6、怎么验证主从节点数据是同步的呢？

 这种主从搭配已过时。
 ----------------------------真正的mongodb分布式---------------------------------------------------
 仲裁结构副本集：
 主节点：master，可读可写；
 从节点：slave，不可读，不可写，只是用来备份；
 仲裁：arbiter，只是监听，不存任何数据，相当于 redis 中的哨兵；
 副本集也不常用，因为仲裁节点挂掉之后，主从节点直接不能数据同步，这个副本集就不能用了；
1、replset目录下创建 master，slave，arbiter目录：
mkdir -p /usr/local/mongodb/shard/replset/master/data
mkdir -p /usr/local/mongodb/shard/replset/master/logs
mkdir -p /usr/local/mongodb/shard/replset/slave/data
mkdir -p /usr/local/mongodb/shard/replset/slave/logs
mkdir -p /usr/local/mongodb/shard/replset/arbiter/data
mkdir -p /usr/local/mongodb/shard/replset/arbiter/logs
2、master文件夹中创建配置文件 mongodb.cfg:
dbpath=/usr/local/mongodb/shard/replset/master/data
logpath=/usr/local/mongodb/shard/replset/master/logs/mongodb.log
logappend=true
fork=true
bind_ip=172.17.11.137
port=29001
shardsvr=true
replSet=shard002  ##表示副本集名称，只要mongod进程的副本集叫这个名称，就是这个副本集里的一个点，这个
副本集里的所有点数据都一样，保证高可用；

slave文件夹中创建配置文件 mongodb.cfg:
dbpath=/usr/local/mongodb/shard/replset/slave/data
logpath=/usr/local/mongodb/shard/replset/slave/logs/mongodb.log
logappend=true
fork=true
bind_ip=172.17.11.137
port=29002
replSet=shard002


arbiter文件夹中创建配置文件 mongodb.cfg:
dbpath=/usr/local/mongodb/shard/replset/arbiter/data
logpath=/usr/local/mongodb/shard/replset/arbiter/logs/mongodb.log
logappend=true
fork=true
bind_ip=172.17.11.137
port=29003
replSet=shard002

3、分别启动服务器端：mongod -f mongodb.cfg

4、客户端连接服务端：mongo --host=172.17.11.137 --port=29001
声明变量：cfg={_id:"shard002",members:[{_id:0,host:'172.17.11.137:29001',priority:9},{_id:1,host:'172.17.11.137:29002',priority:1},{_id:2,host:'172.17.11.137:29003',arbiterOnly:true}]}
priority越大，越有可能是主节点，artiberOnly=true表示该节点为仲裁节点；
初始化：rs.initiate(cfg)
查询状态：rs.status()

---------------------------------
搭建存数据的副本集服务：
1、在 /usr/local/mongodb/ 目录下创建 shard/replset 目录，replset 副本集，用于存数据：
mkdir -p /usr/local/mongodb/shard/replset/replica1/data
mkdir -p /usr/local/mongodb/shard/replset/replica1/logs
mkdir -p /usr/local/mongodb/shard/replset/replica2/data
mkdir -p /usr/local/mongodb/shard/replset/replica2/logs
mkdir -p /usr/local/mongodb/shard/replset/replica3/data
mkdir -p /usr/local/mongodb/shard/replset/replica3/logs
2、在 /usr/local/mongodb/shard/replset/replica1|2|3 中创建mongodb.cfg文件，内容如下：
dbpath=/usr/local/mongodb/shard/replset/replica1 |2 |3/data
logpath=/usr/local/mongodb/shard/replset/replica1 |2 |3/logs/mongodb.log
logappend=true
fork=true
bind_ip=192.168.1.150
port=27001 | 27002 | 27003
replSet=shard001
shardsvr=true  ##表示支持分片

注意：mongodb副本集通过配置文件中的 repliSet=shard001 唯一标识，只要一个 mongod 进程的配置文件中配置了，
repliSet=shard001 那个这个mongod进程就属于 shard001这个副本集；
副本集内部各个 mongo 进程 存的数据是相同的，副本集之间存的数据是并集关系的；

3、启动服务端：./mongod -f mongodb.cfg
4、客户端连接：/usr/local/mongodb/bin/mongo 192.168.1.150:27001;
5、客户端操作：
声明变量：cfg={_id:"shard001",members:[{_id:0,host:'192.168.1.150:27001'},{_id:1,host:'192.168.1.150:27002'},{_id:2,host:'192.168.1.150:27003'}]}
执行函数：rs.initiate(cfg)
查看状态：rs.status()

搭建配置集群服务：
1、/usr/local/mongodb/shard 目录下创建 configsvr/config1 |2 |3 目录:

mkdir -p /usr/local/mongodb/shard/configsvr/config1/data
mkdir -p /usr/local/mongodb/shard/configsvr/config1/logs
mkdir -p /usr/local/mongodb/shard/configsvr/config2/data
mkdir -p /usr/local/mongodb/shard/configsvr/config2/logs
mkdir -p /usr/local/mongodb/shard/configsvr/config3/data
mkdir -p /usr/local/mongodb/shard/configsvr/config3/logs

2、config1 |2 |3 目录下创建mongodb.cfg，vim mongodb.cfg，内容如下：
dbpath=/usr/local/mongodb/shard/configsvr/config1/data
logpath=/usr/local/mongodb/shard/configsvr/config1/logs/mongo.log
logappend=true
fork=true
bind_ip=192.168.1.150
port=28001
replSet=configs  注意：副本集replSet名字必须相同，否则不能组成集群；
configsvr=true

3、启动各服务器：./mongod -f mongodb.cfg  启动服务端规律 = 启动命令 + 配置文件；
注意：服务端都用 mongod 命令启动，取决于后面跟什么配置文件；
4、客户端连接：./mongo --host=192.168.1.150 --port=28001
声明变量：cfg={_id:"configs",members:[{_id:0,host:'192.168.1.150:28001'},{_id:1,host:'192.168.1.150:28002'},{_id:2,host:'192.168.1.150:28003'}]}
执行函数：rs.initiate(cfg)
查看状态：rs.status()

搭建路由服务：路由服务可以是一台

1、/usr/local/mongodb/shard 目录下创建  目录-routesvr：mkdir -p /usr/local/mongodb/shard/routesvr
2、routesvr目录下创建logs目录：mkdir -p /usr/local/mongodb/shard/routesvr/logs
3、routesvr目录下创建 mongodb.cfg 文件 vim mongodb.cfg 内容如下：
configdb=configs/192.168.1.150:28001,192.168.1.150:28002,192.168.1.150:28003  ##configurs代表副本集名字，后面ip：port代表副本集里面机器
logpath=/usr/local/mongodb/shard/routesvr/logs/mongodb.log
logappend=true
fork=true
bind_ip=192.168.1.150
port=30000
4、启动服务端：./mongos -f mongodb.cfg
5、客户端连接服务端：mongo 192.168.1.150:30000
操作：show dbs 结果：config；use config；show collections；

（mongodb主要有三个集群：路由集群，配置集群，数据(分片)集群

副本集 repliSet：多个 mongod 进程组成，各自保存数据一样，保证高可用；
切片 shard：每个副本集可以看做一个切片，各切片之间数据不同，各切片属于并集关系，一个切片保存一部分数据，
所有切片组合起来，保存完整数据，保证高并发；

6、路由客户端操作：
路由服务器添加副本集：
mongos> sh.addShard("shard001/192.168.1.150:27001")
mongos> sh.addShard("shard002/192.168.1.150:29001")
7、切换到 testdb 数据库：use testdb；
对路由中的数据库testdb数据库启用分片：sh.enableSharding("testdb")；
外部将数据保存到路由数据库testdb中，实际上，路由没有保存这个数据，而是根据某种算法，将数据分成几部分，然
后，分别保存到相应的副本集中，外部来路由的数据库testdb取数据时，路由根据相应算法，从各副本集取出数据，组
成完整数据，然后再给外部；
此处报错：Cannot accept sharding commands if not started with --shardsvr；是版本问题，使用3.6版没问题
3.4版有这个问题；

对collection进行分片：
sh.shardCollection("testdb.testcon",{name:"hashed"})，表示对路由服务器中的testdb数据库的testcon集合
启用分片，即这个集合的数据要分成几部分，存在不同的分片中，分法：对数据的name属性的值的求hash值，看hash
值对应副本集的哪个槽位，就分到哪个副本集里面；

8、在路由服务器上面添加数据：mongos > for(var i=0;i<20;i++) db.testcon.insert(name:"tom"+i,age:i)
路由会根据数据的name属性的值的hash值将该数据保存到副本集的相应槽位上，然后，分别来到各自副本集，看数据是否由路
由保存到副本集；

9、路由config库中shards集合与chunks集合：
mongos > use config;
mongos > show collections;
返回：
actionlog
changelog
chunks
lockpings
locks
migrations
mongos
shards
tags
version

redis哨兵机制：哨兵检测每个节点是否挂掉；
redis节点由hash槽组成，hash槽有自己连续编号，例如，一个节点存 [0,128) 号hash槽，下一个节点存 [128,256)
号hash槽；
mongodb与redis集群异曲同工，mongodb中的一个副本集可以理解为redis中的一个节点，redis集群由多个节点组成，
个节点之间属于并集关系，相加到一起得到全部数据，mongodb集群由多个副本集组成，各副本集之间属于并集关系，
相加到一起得到全部数据；
注意：mongodb副本集通过配置文件中的 repliSet=shard001 唯一标识，只要一个 mongod 进程的配置文件中配置了，
repliSet=shard001 那个这个mongod进程就属于 shard001这个副本集，副本集内部各个 mongo 进程 存的数据是相
同的，副本集之间存的数据是并集关系的；
mongodb集群由多个副本集组成，一个副本集相当于一个切片shard，一个切片shard由多个块chunk组成，各副本集之
间数据属于并集（相加）关系；

目前为止，总体感觉：数据给路由，路由根据分片规则，将数据存到各副本集中；
















